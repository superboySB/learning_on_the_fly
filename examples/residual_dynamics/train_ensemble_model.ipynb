{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from orbax.checkpoint import PyTreeCheckpointer\n",
    "\n",
    "from lotf import LOTF_PATH\n",
    "from lotf.utils.residual_dynamics import create_vec_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Ensemble of Residual Dynamics Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Number of Models, Create Vectorized Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "\n",
    "# NOTE: these vectorized functions automatically broadcasts over arbitrary number of ensemble models\n",
    "init_fn, train_fn, predict_fn = create_vec_funcs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (1000, 22)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"example_dataset.csv\"\n",
    "\n",
    "file_path = LOTF_PATH + \"/../examples/residual_dynamics/\" + dataset_name\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "dataset = df.to_numpy()\n",
    "print(f\"Loaded dataset shape: {dataset.shape}\")\n",
    "\n",
    "input_dim = 19\n",
    "output_dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Training Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_init_scale = 1.0    # scale of weight initialization\n",
    "learning_rate = 1e-2       # optimizer learning rate\n",
    "lambda_reg = 1e-3          # weight norm regularization coefficient\n",
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "eval_every = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 | Train MSE: 4.412898063659668 | Total Loss: 4.4180989265441895\n",
      "Epoch 0/100 | Train MSE: 4.686639785766602 | Total Loss: 4.691734790802002\n",
      "Epoch 0/100 | Train MSE: 2.74587082862854 | Total Loss: 2.750821352005005\n",
      "Epoch 10/100 | Train MSE: 0.11662287265062332 | Total Loss: 0.12209775298833847\n",
      "Epoch 10/100 | Train MSE: 0.08662877231836319 | Total Loss: 0.09204016625881195\n",
      "Epoch 10/100 | Train MSE: 0.09959358721971512 | Total Loss: 0.10462775826454163\n",
      "Epoch 20/100 | Train MSE: 0.02277565561234951 | Total Loss: 0.029141608625650406\n",
      "Epoch 20/100 | Train MSE: 0.036559805274009705 | Total Loss: 0.04275143891572952\n",
      "Epoch 20/100 | Train MSE: 0.02065705507993698 | Total Loss: 0.026527877897024155\n",
      "Epoch 30/100 | Train MSE: 0.012339760549366474 | Total Loss: 0.019211947917938232\n",
      "Epoch 30/100 | Train MSE: 0.015150896273553371 | Total Loss: 0.021953297778964043\n",
      "Epoch 30/100 | Train MSE: 0.011963981203734875 | Total Loss: 0.018357669934630394\n",
      "Epoch 40/100 | Train MSE: 0.005908987484872341 | Total Loss: 0.012996762990951538\n",
      "Epoch 40/100 | Train MSE: 0.008055995218455791 | Total Loss: 0.015195842832326889\n",
      "Epoch 40/100 | Train MSE: 0.007642130367457867 | Total Loss: 0.014287343248724937\n",
      "Epoch 50/100 | Train MSE: 0.003977539483457804 | Total Loss: 0.011131374165415764\n",
      "Epoch 50/100 | Train MSE: 0.004713474307209253 | Total Loss: 0.011968246661126614\n",
      "Epoch 50/100 | Train MSE: 0.004153559450060129 | Total Loss: 0.010891780257225037\n",
      "Epoch 60/100 | Train MSE: 0.003146825125440955 | Total Loss: 0.010218339040875435\n",
      "Epoch 60/100 | Train MSE: 0.003134267870336771 | Total Loss: 0.010393526405096054\n",
      "Epoch 60/100 | Train MSE: 0.0024996499996632338 | Total Loss: 0.009185715578496456\n",
      "Epoch 70/100 | Train MSE: 0.002483509946614504 | Total Loss: 0.009432569146156311\n",
      "Epoch 70/100 | Train MSE: 0.002202794421464205 | Total Loss: 0.009391739964485168\n",
      "Epoch 70/100 | Train MSE: 0.0019146365812048316 | Total Loss: 0.008412043564021587\n",
      "Epoch 80/100 | Train MSE: 0.0020311721600592136 | Total Loss: 0.008875221945345402\n",
      "Epoch 80/100 | Train MSE: 0.0017668029759079218 | Total Loss: 0.008823246695101261\n",
      "Epoch 80/100 | Train MSE: 0.0015288626309484243 | Total Loss: 0.007869096472859383\n",
      "Epoch 90/100 | Train MSE: 0.0016850922256708145 | Total Loss: 0.008451473899185658\n",
      "Epoch 90/100 | Train MSE: 0.0014785886742174625 | Total Loss: 0.008418140932917595\n",
      "Epoch 90/100 | Train MSE: 0.0012713887263089418 | Total Loss: 0.007477154955267906\n",
      "Epoch 100/100 | Train MSE: 0.0014551017666235566 | Total Loss: 0.00814331416040659\n",
      "Epoch 100/100 | Train MSE: 0.0011811773292720318 | Total Loss: 0.008042171597480774\n",
      "Epoch 100/100 | Train MSE: 0.0010755072580650449 | Total Loss: 0.007175474427640438\n",
      "Residual model training took 5.57 seconds\n"
     ]
    }
   ],
   "source": [
    "# initialize model params and train states\n",
    "model_params, train_states = init_fn(\n",
    "    learning_rate, jnp.arange(num_models, dtype=jnp.int32)\n",
    ")\n",
    "\n",
    "# prepare dataset\n",
    "X, y = dataset[:, :input_dim], dataset[:, input_dim:]\n",
    "X, y = jnp.array(X, dtype=jnp.float32), jnp.array(y, dtype=jnp.float32)\n",
    "\n",
    "tic = time()\n",
    "train_states = train_fn(train_states, X, y, lambda_reg, num_epochs, eval_every)\n",
    "print(f\"Residual model training took {time() - tic:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model params!\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"my_residual_dynamics_params\"\n",
    "\n",
    "model_path = LOTF_PATH + \"/../checkpoints/residual_dynamics/\" + model_name\n",
    "ckptr = PyTreeCheckpointer()\n",
    "residual_params = train_states.params\n",
    "ckptr.save(model_path, residual_params)\n",
    "print(\"Saved model params!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lotf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
